{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97d11d04-3897-465c-9918-281a0e26fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-2.28.1-py2.py3-none-any.whl (202 kB)\n",
      "     |████████████████████████████████| 202 kB 1.8 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2.0dev,>=1.38.1\n",
      "  Downloading grpcio-1.41.0-cp39-cp39-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "     |████████████████████████████████| 3.9 MB 3.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-cloud-bigquery) (21.0)\n",
      "Collecting google-api-core[grpc]<3.0.0dev,>=1.29.0\n",
      "  Downloading google_api_core-2.1.1-py2.py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 3.2 MB/s            \n",
      "\u001b[?25hCollecting proto-plus>=1.10.0\n",
      "  Downloading proto_plus-1.19.5-py3-none-any.whl (44 kB)\n",
      "     |████████████████████████████████| 44 kB 3.1 MB/s            \n",
      "\u001b[?25hCollecting google-resumable-media<3.0dev,>=0.6.0\n",
      "  Using cached google_resumable_media-2.0.3-py2.py3-none-any.whl (75 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-2.1.0-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-cloud-bigquery) (2.25.1)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.19.0-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "     |████████████████████████████████| 1.0 MB 3.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (58.2.0)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (2.3.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from grpcio<2.0dev,>=1.38.1->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from packaging>=14.3->google-cloud-bigquery) (3.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/lilyfrancus/miniconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery) (0.4.8)\n",
      "Installing collected packages: protobuf, googleapis-common-protos, grpcio, google-crc32c, google-api-core, proto-plus, google-resumable-media, google-cloud-core, google-cloud-bigquery\n",
      "Successfully installed google-api-core-2.1.1 google-cloud-bigquery-2.28.1 google-cloud-core-2.1.0 google-crc32c-1.3.0 google-resumable-media-2.0.3 googleapis-common-protos-1.53.0 grpcio-1.41.0 proto-plus-1.19.5 protobuf-3.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Opens a client to Google BigQuery to pull the data\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "key_path = 'service_key_google_cloud.json'\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)\n",
    "def find_starting_date():\n",
    "    query_string = \"\"\"\n",
    "    \n",
    "    SELECT block_timestamp from `bigquery-public-data.crypto_ethereum.transactions`\n",
    "    where block_number = \n",
    "        (select min(block_number) from `bigquery-public-data.crypto_ethereum.transactions`)\n",
    "    \"\"\"\n",
    "    return client.query(query_string).result().to_dataframe()\n",
    "\n",
    "def find_all_txns_on_date(start, end):\n",
    "    start_timestr = start.strftime('%Y-%m-%d')\n",
    "    end_timestr = end.strftime('%Y-%m-%d')\n",
    "    query_string = f\"\"\"\n",
    "\n",
    "    SELECT *\n",
    "    FROM `bigquery-public-data.crypto_ethereum.transactions`\n",
    "    WHERE block_timestamp BETWEEN '{start_timestr}' AND '{end_timestr}'\n",
    "    \"\"\"\n",
    "    return client.query(query_string).result().to_dataframe()\n",
    "\n",
    "def curved_edges2(edges, pos, dist_ratio=0.2, bezier_precision=20, polarity='random'):\n",
    "    l = edges.shape[0] # number of edges\n",
    "\n",
    "    if polarity == 'random':\n",
    "        # Random polarity of curve\n",
    "        rnd_1 = np.where(np.random.randint(2, size=l)==0, -1, 1)\n",
    "        rnd_2 = np.where(np.random.randint(2, size=l)==0, -1, 1)\n",
    "    else:\n",
    "        # Create a fixed (hashed) polarity column in the case we use fixed polarity\n",
    "        # This is useful, e.g., for animations\n",
    "        rnd_1 = np.where(np.mod(np.vectorize(hash)(edges[:,0])+np.vectorize(hash)(edges[:,1]),2)==0,-1,1)\n",
    "        rnd_2 = np.where(np.mod(np.vectorize(hash)(edges[:,0])+np.vectorize(hash)(edges[:,1]),2)==0,-1,1)\n",
    "    \n",
    "    # Coordinates (x,y) of both nodes for each edge\n",
    "    # e.g., https://stackoverflow.com/questions/16992713/translate-every-element-in-numpy-array-according-to-key\n",
    "    # Note the np.vectorize method doesn't work for all node position dictionaries for some reason\n",
    "    u, inv = np.unique(edges, return_inverse = True)\n",
    "    #print(np.array([pos[x] for x in u])[inv])\n",
    "    coords = np.array([pos[x] for x in u])[inv].reshape([edges.shape[0], edges.shape[1], 3])\n",
    "    coords_node1 = coords[:,0,:]\n",
    "    coords_node2 = coords[:,1,:]\n",
    "    # Swap node1/node2 allocations to make sure the directionality works correctly\n",
    "    should_swap = coords_node1[:,0] > coords_node2[:,0]\n",
    "    coords_node1[should_swap], coords_node2[should_swap] = coords_node2[should_swap], coords_node1[should_swap]\n",
    "    \n",
    "    # Distance for control points\n",
    "    norm = np.sqrt(np.sum((coords_node1-coords_node2)**2, axis=1))\n",
    "    dist = dist_ratio * norm\n",
    "    # Gradients of line connecting node & perpendicular\n",
    "    unit_vector = (coords_node2-coords_node1)/norm[:,None]\n",
    "    perp_vec = np.array([unit_vector[:,0]*unit_vector[:,2], unit_vector[:,1]*unit_vector[:,2], -(unit_vector[:,0]**2+unit_vector[:,1]**2)]).T\n",
    "\n",
    "    coords_node1_displace = coords_node1 + (unit_vector * dist[:,None])\n",
    "    coords_node2_displace = coords_node2 - (unit_vector * dist[:,None])\n",
    "\n",
    "    coords_node1_ctrl = coords_node1_displace + rnd_1[:,None]*(perp_vec*dist[:,None])\n",
    "    coords_node2_ctrl = coords_node2_displace + rnd_2[:,None]*(perp_vec*dist[:,None])\n",
    "\n",
    "    # Combine all these four (x,y) columns into a 'node matrix'\n",
    "    node_matrix = np.array([coords_node1, coords_node1_ctrl, coords_node2_ctrl, coords_node2])\n",
    "    \n",
    "    # Create the Bezier curves and store them in a list\n",
    "    curveplots = []\n",
    "    curve_dict = {}\n",
    "    for i in tqdm(range(l)):\n",
    "        nodes = node_matrix[:,i,:].T\n",
    "        curve = bezier.Curve.from_nodes(nodes).evaluate_multi(np.linspace(0,1,bezier_precision)).T\n",
    "        curveplots.append(curve)\n",
    "        curve_dict[\"-\".join(edges[i])] = curve\n",
    "        \n",
    "    # Return an array of these curves\n",
    "    curves = np.array(curveplots)\n",
    "    return curves, curve_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6007dc47-ad16-4e49-8ede-211c0a3f743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "c = find_starting_date()\n",
    "day = c.iloc[0]['block_timestamp'].date() + timedelta(days=500)\n",
    "next_day = day + timedelta(days=1)\n",
    "zf = find_all_txns_on_date(day, next_day)\n",
    "day_as_timestamp = pd.to_datetime(day).timestamp()\n",
    "timeframe = 8*60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e689a5f5-f5a9-4122-b42f-dbe5f39d6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = zf.copy()\n",
    "df = df.fillna(0)\n",
    "df['is_contract'] = df.apply(lambda row: row['receipt_contract_address'] and not row['to_address'], axis=1)\n",
    "df['value'] = df['value'].apply(float)\n",
    "df['receipt_effective_gas_price'] = df['receipt_effective_gas_price'].apply(float)\n",
    "df['receipt_cumulative_gas_used'] = df['receipt_cumulative_gas_used'].apply(float)\n",
    "df['to_address'] = df.apply(lambda row: row['to_address'] if row['to_address'] else row['receipt_contract_address'], axis=1)\n",
    "df['true_transfer_volume'] = df['value'] + df['receipt_effective_gas_price']*df['receipt_cumulative_gas_used']\n",
    "df['grouping'] = df['block_timestamp'].apply(lambda x: math.floor((x.timestamp() - day_as_timestamp) / timeframe))\n",
    "df['to-from'] = df['from_address'] + '-' + df['to_address']\n",
    "df['from-to'] = df['to_address']  + '-' + df['from_address']\n",
    "df = df[['grouping', 'to-from', 'from-to', 'from_address', 'to_address', 'block_number', 'block_timestamp', 'true_transfer_volume', 'is_contract', 'transaction_type', 'receipt_status']]\n",
    "max_txn_volume = float(max(df['true_transfer_volume']))\n",
    "\n",
    "def specialized_round(x, base=0.02):\n",
    "    return base * round(x/base)\n",
    "\n",
    "\n",
    "df['inverse_exponential_vol_alpha'] = df['true_transfer_volume'].apply(lambda x: \n",
    "    specialized_round(max(\n",
    "        (\n",
    "        ((float(x)/ max_txn_volume) ** (1/5) * 1), \n",
    "        0\n",
    "        )\n",
    "    ))\n",
    ")\n",
    "\n",
    "pivot = df.groupby(['from_address', 'to_address']).agg({ 'true_transfer_volume': sum})\n",
    "pivot.to_csv('temp.csv')\n",
    "pivot = pd.read_csv('temp.csv')\n",
    "daily_transfers = defaultdict(float)\n",
    "for idx, row in pivot.iterrows():\n",
    "    from_add = row['from_address']\n",
    "    to_add = row['to_address']\n",
    "    normal = f\"{from_add}-{to_add}\"\n",
    "    inverse = f\"{to_add}-{from_add}\"\n",
    "    if daily_transfers[inverse] > 0:\n",
    "        daily_transfers[inverse] = daily_transfers[inverse] + row['true_transfer_volume']\n",
    "    else:\n",
    "        daily_transfers[normal] = daily_transfers[normal] + row['true_transfer_volume']\n",
    "pds = []\n",
    "for key, value in daily_transfers.items():\n",
    "    source, target = key.split('-')\n",
    "    if value > 0:\n",
    "        pds.append({\"source\": source, \"target\": target, \"weight\": value/10**18})\n",
    "cf = pd.DataFrame(pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8cfb26-17a4-479a-afb7-c99cc36b7464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Oct 14, 2021 8:48:37 PM org.netbeans.modules.masterfs.watcher.Watcher getNotifierForPlatform\n",
      "INFO: Native file watcher is disabled\n",
      "Oct 14, 2021 8:48:37 PM org.gephi.utils.CharsetToolkit guessEncoding\n",
      "INFO: Detected encoding UTF-8 in XML file\n",
      "Oct 14, 2021 8:48:38 PM org.gephi.io.processor.plugin.DefaultProcessor process\n",
      "INFO: # Nodes loaded: 16,938\n",
      "Oct 14, 2021 8:48:38 PM org.gephi.io.processor.plugin.DefaultProcessor process\n",
      "INFO: # Edges loaded: 23,770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************25%\n",
      "*************************50%\n",
      "*************************75%\n",
      "*************************100%\n",
      "Time = 13.915s\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import forceatlas2\n",
    "import pandas as pd\n",
    "\n",
    "G = nx.from_pandas_edgelist(cf, source='source', target='target', edge_attr=['weight'])\n",
    "nx.write_gexf(G, 'test.gexf')\n",
    "forceatlas2.forceatlas2('test.gexf', target_change_per_node=0)\n",
    "\n",
    "coords = pd.read_csv('test.gexf.coords.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce27a41-a76b-4b55-9956-bb3d21ddde2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q1/ln7stbps0jd3gnmwzl9crfzh0000gn/T/ipykernel_35162/3345213128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbezier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_multiarray_umath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inspect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetargspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import numpy as np\n",
    "import bezier\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from collections import defaultdict \n",
    "\n",
    "layt_coords = coords[['x', 'y', 'z']].values.tolist()\n",
    "pds = pd.DataFrame(pds)\n",
    "g = ig.Graph.DataFrame(pds, directed=False)\n",
    "\n",
    "#layt = g.layout_fruchterman_reingold(dim=3)\n",
    "positions = dict(zip([v.attributes()[\"name\"] for v in np.array(g.vs)], layt_coords))\n",
    "subset = pds[['source', 'target']]\n",
    "edges = np.array([tuple(x) for x in subset.to_numpy()])\n",
    "splines, splines_dict = curved_edges2(edges, positions)\n",
    "\n",
    "node_dict = {v['name']: idx for idx,v in enumerate(list(g.vs))}\n",
    "Edges=[(node_dict[pds.iloc[k]['source']], node_dict[pds.iloc[k]['target']]) for k in range(len(pds))]\n",
    "Xn=[]\n",
    "Yn=[]\n",
    "Zn=[]\n",
    "\n",
    "for k in tqdm(range(len(g.vs))):\n",
    "  [x, y, z] = layt_coords[k]\n",
    "  Xn.append(x)\n",
    "  Yn.append(y)\n",
    "  Zn.append(z)\n",
    "\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "Ze=[]\n",
    "\n",
    "opacities = defaultdict(float)\n",
    "\n",
    "def insert_nones_per_line_segment(arr):\n",
    "    c = [*np.arange(0, len(arr), 2), len(arr)]\n",
    "    new_arr = []\n",
    "    for i in range(len(c)-1):\n",
    "        new_arr += [*arr[c[i]:c[i+1]],None]\n",
    "    return new_arr\n",
    "    \n",
    "for node_tup, splines in tqdm(splines_dict.items()):\n",
    "    Xe += [(node_tup, [*splines[:,0],None],)]\n",
    "    Ye += [(node_tup, [*splines[:,1],None])]\n",
    "    Ze += [(node_tup, [*splines[:,2],None])]\n",
    "line_traces = [go.Scatter3d(x=[*sp[:,0],None], y=[*sp[:,1],None], z=[*sp[:,2],None],mode='lines', opacity=0.8, line=dict(dash='solid', color='rgb(255,255,255)', width=1),hoverinfo='none') for node_tup, sp in tqdm(splines_dict.items())] \n",
    "\n",
    "STAR_COLOR_PALETTE = [\n",
    "[175, 201, 255],\n",
    "[199, 216, 255],\n",
    "[255, 244, 243],\n",
    "[255, 229, 207],\n",
    "[255, 217, 178],\n",
    "[255, 199, 142],\n",
    "[255, 166, 81],\n",
    "]\n",
    "\n",
    "\n",
    "def create_node_colors(color_arr, opacity):\n",
    "    rgb_str = \", \".join([str(i) for i in color_arr])\n",
    "    return \"rgba(\" + rgb_str + \", \" + str(opacity) + \")\"\n",
    "\n",
    "import random\n",
    "\n",
    "d = [min(v.degree()+1, 25) for v in list(g.vs)]\n",
    "\n",
    "node_fixed_colors = [(node.attributes()[\"name\"], random.choice(STAR_COLOR_PALETTE)) for node in list(g.vs)]\n",
    "\n",
    "trace2=go.Scatter3d(x=Xn, y=Yn, z=Zn, mode='markers', name='actors', \n",
    "                   marker=dict(symbol='circle', size=d, color=[create_node_colors(color,1) for node, color in node_fixed_colors] , \n",
    "                      line=dict(color='rgb(50,50,50)', width=0)), hoverinfo='text')\n",
    "\n",
    "axis=dict(showbackground=False, showline=False, zeroline=False, showgrid=False, showticklabels=False, title='')\n",
    "\n",
    "layout = go.Layout(\n",
    "    width=4000,\n",
    "    height=4000,\n",
    "    showlegend=False,\n",
    "    scene=dict(\n",
    "        xaxis=dict(axis),\n",
    "        yaxis=dict(axis),\n",
    "        zaxis=dict(axis),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type=\"buttons\",\n",
    "        buttons=[dict(label=\"Play\",\n",
    "            method=\"animate\",\n",
    "            args=[None]\n",
    "        )]\n",
    "    )]\n",
    ")\n",
    "\n",
    "def create_data_for_frame(k, df):\n",
    "    print(k)\n",
    "    time_slice = df[df['grouping']==k]\n",
    "    tos = set(time_slice['to-from']).union(set(time_slice['from-to']))\n",
    "    active_nodes = set([a for b in tos for a in b.split('-')])\n",
    "    opacities = defaultdict(float)\n",
    "    for index, row in time_slice.iterrows():\n",
    "        if opacities[row['from-to']] > 0:\n",
    "            opacities[row['from-to']] = row['inverse_exponential_vol_alpha']\n",
    "        else:\n",
    "            opacities[row['to-from']] = row['inverse_exponential_vol_alpha']\n",
    "    traces_by_opacity = defaultdict(list)\n",
    "    #print(set(opacities.keys()).difference(set(splines_dict.keys()).union(set(map(lambda x: x.split(\"-\")[1] + \"-\" + x.split(\"-\")[0], splines_dict.keys())))))\n",
    "    for node_tup, opacity in opacities.items():\n",
    "        inv_node_tup = node_tup.split(\"-\")[1] + \"-\" + node_tup.split(\"-\")[0]\n",
    "        if node_tup in splines_dict or inv_node_tup in splines_dict:\n",
    "            splines = splines_dict[node_tup] if node_tup in splines_dict else splines_dict[inv_node_tup]\n",
    "            traces_by_opacity[opacity].append(splines)\n",
    "    line_traces = []\n",
    "    all_data = []\n",
    "    for opacity, traces in traces_by_opacity.items():\n",
    "        new_Xe = []\n",
    "        new_Ye = []\n",
    "        new_Ze = []\n",
    "        for trace in traces:\n",
    "            new_Xe += [*trace[:,0],None]\n",
    "            new_Ye += [*trace[:,1],None]\n",
    "            new_Ze += [*trace[:,2],None]\n",
    "        all_data.append(go.Scatter3d(x=new_Xe, y=new_Ye, z=new_Ze, mode='lines', opacity=opacity, line=dict(dash='solid', color='rgb(200,200,200)', width=3),hoverinfo='none'))\n",
    "    return [\n",
    "        go.Scatter3d(x=Xn, y=Yn, z=Zn, mode='markers', name='actors', \n",
    "            marker=dict(symbol='circle', size=d, color=[create_node_colors(color, 1) if node in active_nodes else 'rgba(50,50,50,0.1)' for node, color in node_fixed_colors], \n",
    "            line=dict(color='rgb(50,50,50)', width=0)), hoverinfo='text'),   \n",
    "    ] + all_data \n",
    "\n",
    "\n",
    "\n",
    "NUM_FRAMES = int(1440/8)\n",
    "def rotate_z(x, y, z, theta):\n",
    "    w = x+1j*y\n",
    "    return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
    "\n",
    "frames = []\n",
    "x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
    "data_for_all_frames = []\n",
    "x_y_z_for_all_frames = []\n",
    "max_traces_per_frame = -1\n",
    "for k in range(NUM_FRAMES):\n",
    "    xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -6.2*(k/NUM_FRAMES))\n",
    "    traces = create_data_for_frame(k,df)\n",
    "    if len(traces) > max_traces_per_frame:\n",
    "        max_traces_per_frame = len(traces)\n",
    "    data_for_all_frames.append(traces)\n",
    "    x_y_z_for_all_frames.append({ \"x\": xe, \"y\": ye, \"z\": ze })\n",
    "dummy_line_trace = max_traces_per_frame * [go.Scatter3d(x=[], y=[], z=[], mode='lines', line=dict(dash='solid', color='rgb(255,255,255)', width=2),hoverinfo='none')]\n",
    "for idx, traces in enumerate(data_for_all_frames):\n",
    "    length = len(traces)\n",
    "    data_for_all_frames[idx] = data_for_all_frames[idx][1:] + dummy_line_trace[length+1:] + [data_for_all_frames[idx][0]]\n",
    "#    print(data_for_all_frames[idx])\n",
    "frames = [go.Frame(data=data, layout=dict(scene=dict(camera=dict(eye=x_y_z_for_all_frames[idx])))) for idx, data in tqdm(enumerate(data_for_all_frames))]\n",
    "#layout=\n",
    "data= [trace2, dummy_line_trace]\n",
    "#print(data)\n",
    "axis=dict(showbackground=False, showline=False, zeroline=False, showgrid=False, showticklabels=False, title='')\n",
    "layout = go.Layout(\n",
    "    width=4000,\n",
    "    height=4000,\n",
    "    showlegend=False,\n",
    "    scene=dict(\n",
    "        xaxis=dict(axis),\n",
    "        yaxis=dict(axis),\n",
    "        zaxis=dict(axis),\n",
    "    ),\n",
    "    updatemenus=[dict(\n",
    "        type=\"buttons\",\n",
    "        buttons=[dict(label=\"Play\",\n",
    "            method=\"animate\",\n",
    "            args=[None]\n",
    "        )]\n",
    "    )]\n",
    ")\n",
    "fig=go.Figure(data=data_for_all_frames[0], frames=frames, layout=layout)\n",
    "img_width = 5000\n",
    "img_height = 5000\n",
    "scale_factor = 0.3\n",
    "\n",
    "# Add invisible scatter trace.\n",
    "# This trace is added to help the autoresize logic work.\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, img_width * scale_factor],\n",
    "        y=[0, img_height * scale_factor],\n",
    "        mode=\"markers\",\n",
    "        marker_opacity=1\n",
    "    )\n",
    ")\n",
    "fig.update_layout(transition = {'duration': 10})\n",
    "\n",
    "# Configure axes\n",
    "fig.update_xaxes(\n",
    "    visible=False,\n",
    "    range=[0, img_width * scale_factor]\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    visible=False,\n",
    "    range=[0, img_height * scale_factor],\n",
    "    # the scaleanchor attribute ensures that the aspect ratio stays constant\n",
    "    scaleanchor=\"x\"\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "imago = Image.open('./hubble-1632627.png')\n",
    "\n",
    "fig.add_layout_image(\n",
    "    dict(\n",
    "        x=0,\n",
    "        sizex=img_width * scale_factor,\n",
    "        y=img_height * scale_factor,\n",
    "        sizey=img_height * scale_factor,\n",
    "        xref=\"x\",\n",
    "        yref=\"y\",\n",
    "        opacity=1.0,\n",
    "        layer=\"below\",\n",
    "        sizing=\"stretch\",\n",
    "        source=imago)\n",
    ")\n",
    "\n",
    "# Configure other layout\n",
    "fig.update_layout(\n",
    "    width=img_width * scale_factor,\n",
    "    height=img_height * scale_factor,\n",
    "    margin={\"l\": 0, \"r\": 0, \"t\": 0, \"b\": 0},\n",
    ")\n",
    "\n",
    "# Disable the autosize on double click because it adds unwanted margins around the image\n",
    "# More detail: https://plotly.com/python/configuration-options/\n",
    "fig.show(config={'doubleClick': 'reset'})\n",
    "\n",
    "\n",
    "iplot(fig, filename='Les-Miserables')\n",
    "fig.write_html('hello.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7147ecf-b720-4a8d-b9d9-ef7038f09dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
